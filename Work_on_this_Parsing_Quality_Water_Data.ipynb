{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps (as of November 12, 2018)\n",
    "We have our network! But now we need to calculate the values.\n",
    "\n",
    "**Audrey**\n",
    "* [ ] Make sure all of the values we have are measured by micrograms/L!!!  \n",
    "* [ ] Do conversions for all values that aren't micrograms/L\n",
    "* [ ] Revamp code to only include the things we used  \n",
    "* [ ] Calculate values like the average degree, etc.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water Quality Network\n",
    "For our network project, Cassie and I are thinking of creating a bipartite network where the nodes are pollutants and the links are water facilities whose measurements of those pollutants are above the threshold. By doing this linking, we hope to see what the biggest pollutants are, how pollutants might connect to one another, and if there are any pollutants that we should be worried about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sources\n",
    "We got our data from USGS (U.S. Geological Survey). I'll need to get the exact link later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MUST PIP INSTALL\n",
    "* numpy\n",
    "* pandas\n",
    "* matplotlib\n",
    "* xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from io import StringIO\n",
    "import matplotlib.pyplot as plt\n",
    "from networkx.algorithms import bipartite\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the Quality data\n",
    "Since I'm not too familiar with the data, let's load it in and take a look. There's some preliminary things that I do know, which will be come prevelant when you look at the code. For instance, you can break up the code into chunks by splitting on instances of \"#\\n\". The # comes from the file header and most \"sections\" within the header are separated by # followed by a new line. The last item of the split is the actual data.\n",
    "\n",
    "Let's start by loading in everything!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_quality_data(file_name):\n",
    "    quality_data = []\n",
    "    with open(file_name, 'r') as file:\n",
    "        quality_data = file.read().split(\"#\\n\")\n",
    "\n",
    "    if not quality_data:\n",
    "        print(\"File {} was unable to be read.\".format(file_name))\n",
    "    return quality_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sections: 16\n",
      "2nd section:\n",
      "# U.S. Geological Survey\n",
      "# \n",
      "# This file contains selected water-quality data for stations in the National Water Information \n",
      "# System water-quality database.  Explanation of codes found in this file are followed by\n",
      "# the retrieved data.\n",
      "\n",
      "Number of characters in actual data: 9736982\n"
     ]
    }
   ],
   "source": [
    "file_name = \"LA_Water_Quality_Data.txt\"\n",
    "quality_data = load_quality_data(file_name)\n",
    "print(\"Number of sections:\", len(quality_data))\n",
    "print(\"2nd section:\", quality_data[2], sep = \"\\n\")\n",
    "print(\"Number of characters in actual data:\", len(quality_data[15]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We have 15 chunks of text when doing that split (which feels a bit better than doing it line-by-line). Here's a breakdown of what's inside:\n",
    "    #  0:                               #  8: coll_ent_cd  \n",
    "    #  1: File created...               #  9: medium_cd  \n",
    "    #  2: U.S. Geological Survey        # 10: tu_id  \n",
    "    #  3: The data you have...          # 11: body_part_id  \n",
    "    #  4: To view additional...         # 12: remark_cd  \n",
    "    #  5: Param_id      - parameter     # 13: Data for the following sites...  \n",
    "    #  6: sample_start_time_datum_cd    # 14: WARNING: some spreadsheet...  \n",
    "    #  7: tm_datum_rlbty_cd             # 15: Data!  \n",
    "\n",
    "I've already glanced at the file in Excel and figured out how to parse all of the parameters and their descriptions, which will probably be useful later on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "There are about a thousand parameters, most of them are in the format of a p + 5-digit number (i.e. `p62168`). Not very descriptive, but the 6th entry of our data header has the actual descriptions for each parameter. These descriptions have a lot of information, such as the pollutant name, filtered vs unfiltered, and units of measurement.\n",
    "\n",
    "We want to later extract the pollutant and if the sample was filtered or unfiltered. For now, let's just make a dictionary to get the description for the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_params_def`: function\n",
    "* Input is `param_header`, which is a giant string with `\"\\n\"` characters separating each line\n",
    "* Each \"line\" has the `p#####` parameter label and the description, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs the part of the header that contains the parameter label followed by its meaning\n",
    "# outputs a dictionary where the key is the label (lower case) and the value is the description\n",
    "def get_params_def(param_header):\n",
    "    params_def_dict = {} # Key is p#####, value is description, which contains the pollutant\n",
    "    params = param_header.split(\"\\n\")\n",
    "    params_pattern = re.compile(\"# +(\\w+) +- +(.+)\")\n",
    "\n",
    "    for param in params:\n",
    "        a = params_pattern.search(param)\n",
    "\n",
    "        if a: \n",
    "            altered_description = re.sub(\"  +\", \", \", \n",
    "                                         a.group(2).replace(\"filtered (\", \"filtered, (\"))\n",
    "            params_def_dict[a.group(1).lower()] = altered_description\n",
    "            #print(a.group(1) + \":\", a.group(2).split(',')[-1])\n",
    "\n",
    "    return params_def_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters measured: 1046\n",
      "Example:\n",
      "\tkey   = p62168\n",
      "\tvalue = Fipronil sulfone, water, filtered, recoverable, micrograms per liter\n"
     ]
    }
   ],
   "source": [
    "params_def_dict = get_params_def(quality_data[5])\n",
    "print(\"Total number of parameters measured:\", len(params_def_dict))\n",
    "ex_param_dict = list(params_def_dict.keys())[len(params_def_dict.keys())//2]\n",
    "print(\"Example:\\n\\tkey   = {}\\n\\tvalue = {}\".format(ex_param_dict, params_def_dict[ex_param_dict]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the list of all the parameters, but we're really only interested in a few of the metadata ones and we'll need to go through the measurement ones to determine which ones we want.\n",
    "\n",
    "Since we know the metadata parameters we want, we can put them into `needed_params`:\n",
    "* the site number, `site_no`\n",
    "* the date the measurement was taken `sample_dt`\n",
    "* the time the measurement was taken `sample_tm`\n",
    "\n",
    "Since we want to go through specifically the measurements (p + 5-digit params), we'll create a list of all those named `data_params` that we'll use later to subset the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only the parameters we're interested in, which are the site info, date/times of sampling,\n",
    "#  and all of the measurements (the p + 5-digit params)\n",
    "needed_params = [\"site_no\", \"sample_dt\", \"sample_tm\"]\n",
    "data_params = [param for param in params_def_dict if param[0] == \"p\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Data \n",
    "Now that we have the parameters, we can grab the actual measurements from `quality_data`. The data is a tab and newline-separated chunk of text where the tabs separate parameter measurements and the newlines separate measurements of a specific time. The data also has an extra row underneath the header that doesn't seem of any use to us, so we can disregard it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = quality_data[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15412306785583496\n"
     ]
    }
   ],
   "source": [
    "# Time: 0.16467714309692383\n",
    "start_time = time.time()\n",
    "subbed_test = re.sub(\"\\t[AERMUV]\", \n",
    "              \"\\t\", test.replace(\"USGS\", \n",
    "                                 \"~~~~\").replace(\" \", \n",
    "                                                 \"\").replace(\"<\", \n",
    "                                                             \"\").replace(\">\",\n",
    "                                                                         \"\")).replace(\"~~~~\", \n",
    "                                                                                      \"USGS\")\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Time: 0.2593867778778076\n",
    "# start_time = time.time()\n",
    "# subbed_test_2 = re.sub(\"\\t[AERMUV]\", \"\\t\", re.sub(\"[ <>]\", \"\", test.replace(\"USGS\", \"~~~~\"))).replace(\"~~~~\", \"USGS\")\n",
    "# print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Time: 0.26819419860839844\n",
    "# start_time = time.time()\n",
    "# subbed_test_3 = test.replace(\n",
    "#      \"USGS\", \"~~~~\").replace(\n",
    "#             \" \", \"\").replace(\n",
    "#             \"<\", \"\").replace(\n",
    "#             \">\", \"\").replace(\n",
    "#         \"\\tA\", \"\\t\").replace(\n",
    "#         \"\\tE\", \"\\t\").replace(\n",
    "#         \"\\tR\", \"\\t\").replace(\n",
    "#         \"\\tM\", \"\\t\").replace(\n",
    "#         \"\\tU\", \"\\t\").replace(\n",
    "#         \"\\tV\", \"\\t\").replace(\n",
    "#      \"~~~~\", \"USGS\")\n",
    "# print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_per_param = {param:\"float\" if param[0]==\"p\" else \"str\" for param in params_def_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7763, 1046)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency_cd</th>\n",
       "      <th>site_no</th>\n",
       "      <th>sample_dt</th>\n",
       "      <th>sample_tm</th>\n",
       "      <th>sample_end_dt</th>\n",
       "      <th>sample_end_tm</th>\n",
       "      <th>sample_start_time_datum_cd</th>\n",
       "      <th>tm_datum_rlbty_cd</th>\n",
       "      <th>coll_ent_cd</th>\n",
       "      <th>medium_cd</th>\n",
       "      <th>...</th>\n",
       "      <th>p99856</th>\n",
       "      <th>p99871</th>\n",
       "      <th>p99931</th>\n",
       "      <th>p99947</th>\n",
       "      <th>p99958</th>\n",
       "      <th>p99959</th>\n",
       "      <th>p99963</th>\n",
       "      <th>p99972</th>\n",
       "      <th>p99994</th>\n",
       "      <th>p99995</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USGS</td>\n",
       "      <td>332031118504001</td>\n",
       "      <td>2000-10-24</td>\n",
       "      <td>14:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDT</td>\n",
       "      <td>T</td>\n",
       "      <td>USGS-WRD</td>\n",
       "      <td>WG</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USGS</td>\n",
       "      <td>333420118060501</td>\n",
       "      <td>2000-11-09</td>\n",
       "      <td>09:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PST</td>\n",
       "      <td>T</td>\n",
       "      <td>USGS-WRD</td>\n",
       "      <td>WG</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1046 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  agency_cd          site_no   sample_dt sample_tm sample_end_dt  \\\n",
       "0      USGS  332031118504001  2000-10-24     14:30           NaN   \n",
       "1      USGS  333420118060501  2000-11-09     09:30           NaN   \n",
       "\n",
       "  sample_end_tm sample_start_time_datum_cd tm_datum_rlbty_cd coll_ent_cd  \\\n",
       "0           NaN                        PDT                 T    USGS-WRD   \n",
       "1           NaN                        PST                 T    USGS-WRD   \n",
       "\n",
       "  medium_cd   ...   p99856 p99871  p99931  p99947  p99958  p99959  p99963  \\\n",
       "0        WG   ...      NaN    0.0     NaN     NaN     NaN     NaN     NaN   \n",
       "1        WG   ...      NaN    0.0     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "   p99972  p99994  p99995  \n",
       "0     NaN     NaN     NaN  \n",
       "1     NaN     NaN     NaN  \n",
       "\n",
       "[2 rows x 1046 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_to_use = pd.read_csv(StringIO(subbed_test), sep='\\t', \n",
    "                          dtype=types_per_param, header=0, skiprows=[1])\n",
    "# I find this a bit concerning...: https://stackoverflow.com/questions/24251219/pandas-read-csv-low-memory-and-dtype-options\n",
    "# I'd want to specify type, but it seems like there's a lot of strings within supposedly numerical columns...\n",
    "print(data_to_use.shape)\n",
    "display(data_to_use.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've loaded in all the data successfully, let's get the subset of the data that only contains measurements. Calling it `data_to_use_numbers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p00003</th>\n",
       "      <th>p00004</th>\n",
       "      <th>p00005</th>\n",
       "      <th>p00008</th>\n",
       "      <th>p00009</th>\n",
       "      <th>p00010</th>\n",
       "      <th>p00011</th>\n",
       "      <th>p00020</th>\n",
       "      <th>p00021</th>\n",
       "      <th>p00025</th>\n",
       "      <th>...</th>\n",
       "      <th>p99856</th>\n",
       "      <th>p99871</th>\n",
       "      <th>p99931</th>\n",
       "      <th>p99947</th>\n",
       "      <th>p99958</th>\n",
       "      <th>p99959</th>\n",
       "      <th>p99963</th>\n",
       "      <th>p99972</th>\n",
       "      <th>p99994</th>\n",
       "      <th>p99995</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>973.0</td>\n",
       "      <td>90.7</td>\n",
       "      <td>99.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1034 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   p00003  p00004  p00005  p00008  p00009  p00010  p00011  p00020  p00021  \\\n",
       "0     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "1     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "2     NaN     NaN     NaN     NaN     NaN    18.5     NaN     NaN     NaN   \n",
       "3     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "4     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "   p00025   ...    p99856  p99871  p99931  p99947  p99958  p99959  p99963  \\\n",
       "0     NaN   ...       NaN     0.0     NaN     NaN     NaN     NaN     NaN   \n",
       "1     NaN   ...       NaN     0.0     NaN     NaN     NaN     NaN     NaN   \n",
       "2     NaN   ...       NaN     0.0     NaN     NaN     NaN     NaN     NaN   \n",
       "3     NaN   ...       NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "4     NaN   ...       NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "   p99972  p99994  p99995  \n",
       "0     NaN     NaN     NaN  \n",
       "1     NaN     NaN     NaN  \n",
       "2   973.0    90.7    99.8  \n",
       "3     NaN     NaN     NaN  \n",
       "4     NaN     NaN     NaN  \n",
       "\n",
       "[5 rows x 1034 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_use_numbers = data_to_use[data_params]\n",
    "data_to_use_numbers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#string = data_to_use_numbers.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#string.replace(\"NaN\", \"~~~\").replace(\"\\t\", \"===============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_to_use.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_to_use_numbers = data_to_use_numbers.replace(\"[<> A-Za-z]\", \"\", regex=True)\n",
    "#data_to_use_numbers = data_to_use_numbers.replace(\" \", \"\", regex=True)\n",
    "#data_to_use_numbers = data_to_use_numbers.replace(r'^$', np.nan, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_to_use_numbers = data_to_use_numbers.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(data_to_use_numbers.dtypes == \"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_data = pd.concat([data_to_use[needed_params], data_to_use_numbers], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting params into filtered and unfiltered\n",
    "* unfiltered = grab the ground water as is - you have extra sediment somehow\n",
    "* filtered = you filter out the ground water \n",
    "* do analysis with filtered and unfiltered, but DON'T MIX\n",
    "* higher pollution for unfiltered properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note\n",
    "There's some descrepencies in these parameters. We'll deal with this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_params_by(params_def_dict, by=\"filtered\", opposite=False):\n",
    "    filtered_params = {}\n",
    "    for param_def in params_def_dict.items():\n",
    "        component_def = param_def[1].split(\", \")\n",
    "        component = component_def[0].lower()\n",
    "        \n",
    "        if (opposite and by not in component_def) or (not opposite and by in component_def):\n",
    "            if component not in filtered_params:\n",
    "                filtered_params[component] = []\n",
    "            filtered_params[component].append(param_def[0])\n",
    "            \n",
    "    return filtered_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#said_filtered_pollutants = filter_params_by(params_def_dict, by=\"filtered\", opposite=False)\n",
    "all_filtered_params = filter_params_by(params_def_dict, by=\"unfiltered\", opposite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is writing the params into a file\n",
    "#unfiltered_file = open(\"Unfiltered_params.txt\", \"w\")\n",
    "#filtered_file = open(\"Filtered_params.txt\", \"w\")\n",
    "#\n",
    "#for param in unfiltered_params.items():\n",
    "#    formatSTR = param[0] + \"\\t\" + \"\\t\".join(param[1]) + \"\\r\\n\"\n",
    "#    unfiltered_file.write(formatSTR.lower())\n",
    "#unfiltered_file.close()\n",
    "#for param in filtered_params.items():\n",
    "#    formatSTR = param[0] + \"\\t\" + \"\\t\".join(param[1]) + \"\\r\\n\"\n",
    "#    filtered_file.write(formatSTR.lower())\n",
    "#filtered_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Step: Getting the pollutants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pollutant_file = pd.ExcelFile(\"Thresholds_hh_USGScompatible.xlsx\")\n",
    "# convert_to_str = {name:str for name in pd.read_excel(\"Thresholds_hh_USGScompatible.xlsx\").columns.values.tolist()}\n",
    "# pollutant_info = pollutant_file.parse(converters=convert_to_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pollutant_info = pollutant_info[pollutant_info[\"Pollutant (P = priority pollutant)\"].notna()]\n",
    "# pollutant_info[\"Pollutant (P = priority pollutant)\"] = pollutant_info[\"Pollutant (P = priority pollutant)\"].str.strip()\n",
    "# pollutant_info[\"Pollutant (P = priority pollutant)\"] = pollutant_info[\"Pollutant (P = priority pollutant)\"].str.lower()\n",
    "# #pollutant_info[\"Human Health for the consumption of\\xa0Water + Organism (µg/L)\"] = pollutant_info[\"Human Health for the consumption of\\xa0Water + Organism (µg/L)\"].astype(str)\n",
    "# pollutant_info[\"Human Health for the consumption of\\xa0Water + Organism (µg/L)\"] = pollutant_info[\"Human Health for the consumption of\\xa0Water + Organism (µg/L)\"].str.replace(\"<\", \"\")\n",
    "# pollutant_info[\"Human Health for the consumption of\\xa0Water + Organism (µg/L)\"] = pollutant_info[\"Human Health for the consumption of\\xa0Water + Organism (µg/L)\"].str.strip()\n",
    "# has_ranges = pollutant_info[\"Human Health for the consumption of\\xa0Water + Organism (µg/L)\"].str.contains(\"-\")\n",
    "# ranges = pollutant_info[has_ranges]\n",
    "# pollutant_info = pollutant_info[~has_ranges]\n",
    "# pollutant_info[\"Human Health for the consumption of\\xa0Water + Organism (µg/L)\"] = pd.to_numeric(pollutant_info[\"Human Health for the consumption of\\xa0Water + Organism (µg/L)\"])\n",
    "# pollutant_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Where we got the columns with the same pollutant names\n",
    "# common_pollutants_p = []\n",
    "# reverse_params_def_dict = {}\n",
    "# pollutant_info[\"Pollutant (P = priority pollutant)\"]=pollutant_info[\"Pollutant (P = priority pollutant)\"].str.lower()\n",
    "# a = pollutant_info[\"Pollutant (P = priority pollutant)\"]\n",
    "# a = a[a.notna()]\n",
    "# for pollutant in a:\n",
    "#     pollutant = pollutant\n",
    "#     if pollutant in all_filtered_params:\n",
    "#         for column in all_filtered_params[pollutant]:\n",
    "#             common_pollutants_p.append(column)\n",
    "#             reverse_params_def_dict[column] = pollutant\n",
    "# #reverse_params_def_dict\n",
    "# #common_pollutants_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse_params_def_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_data = pd.concat([data_to_use[needed_params], data_to_use_numbers[common_pollutants_p]], axis=1)\n",
    "# #data_to_use_subset.head()\n",
    "\n",
    "# #total_data.notna().sum() # <- this is useful when looking at how many values each column has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common_pollutants_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try the CA Pollutants instead "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_pollutant_file = pd.ExcelFile(\"CA_thresholds_compliation_filtered.xlsx\")\n",
    "ca_pollutant_info = ca_pollutant_file.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name1</th>\n",
       "      <th>Organic_Inorganic</th>\n",
       "      <th>CA_Prim_MCL</th>\n",
       "      <th>CA_Prim_MCL_2</th>\n",
       "      <th>CA_Prim_MCL_unit</th>\n",
       "      <th>CA_Prim_MCL_date</th>\n",
       "      <th>CA_Sec_MCL</th>\n",
       "      <th>CA_Sec_MCL_2</th>\n",
       "      <th>CA_Sec_MCL_unit</th>\n",
       "      <th>CA_Sec_MCL_date</th>\n",
       "      <th>...</th>\n",
       "      <th>CA_BayEst_Health_unit</th>\n",
       "      <th>CA_BayEst_Health_date</th>\n",
       "      <th>NAWQC_Health_WF</th>\n",
       "      <th>NAWQC_Health_WF_2</th>\n",
       "      <th>NAWQC_Health_WF_unit</th>\n",
       "      <th>NAWQC_Health_WF_date</th>\n",
       "      <th>NAWQC_Health_F</th>\n",
       "      <th>NAWQC_Health_F_2</th>\n",
       "      <th>NAWQC_Health_F_unit</th>\n",
       "      <th>NAWQC_Health_F_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acenaphthene</td>\n",
       "      <td>Organic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000-05-18</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-06-29</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acenaphthylene</td>\n",
       "      <td>Organic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acetochlor</td>\n",
       "      <td>Organic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acetone</td>\n",
       "      <td>Organic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acetonitrile</td>\n",
       "      <td>Organic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name1 Organic_Inorganic  CA_Prim_MCL  CA_Prim_MCL_2  \\\n",
       "0    Acenaphthene           Organic          NaN            NaN   \n",
       "1  Acenaphthylene           Organic          NaN            NaN   \n",
       "2      Acetochlor           Organic          NaN            NaN   \n",
       "3         Acetone           Organic          NaN            NaN   \n",
       "4    Acetonitrile           Organic          NaN            NaN   \n",
       "\n",
       "  CA_Prim_MCL_unit CA_Prim_MCL_date  CA_Sec_MCL  CA_Sec_MCL_2 CA_Sec_MCL_unit  \\\n",
       "0              NaN              NaT         NaN           NaN             NaN   \n",
       "1              NaN              NaT         NaN           NaN             NaN   \n",
       "2              NaN              NaT         NaN           NaN             NaN   \n",
       "3              NaN              NaT         NaN           NaN             NaN   \n",
       "4              NaN              NaT         NaN           NaN             NaN   \n",
       "\n",
       "  CA_Sec_MCL_date         ...           CA_BayEst_Health_unit  \\\n",
       "0             NaT         ...                             NaN   \n",
       "1             NaT         ...                             NaN   \n",
       "2             NaT         ...                             NaN   \n",
       "3             NaT         ...                             NaN   \n",
       "4             NaT         ...                             NaN   \n",
       "\n",
       "   CA_BayEst_Health_date NAWQC_Health_WF NAWQC_Health_WF_2  \\\n",
       "0             2000-05-18            70.0               NaN   \n",
       "1                    NaT             NaN               NaN   \n",
       "2                    NaT             NaN               NaN   \n",
       "3                    NaT             NaN               NaN   \n",
       "4                    NaT             NaN               NaN   \n",
       "\n",
       "   NAWQC_Health_WF_unit  NAWQC_Health_WF_date NAWQC_Health_F NAWQC_Health_F_2  \\\n",
       "0                   NaN            2015-06-29           90.0              NaN   \n",
       "1                   NaN                   NaT            NaN              NaN   \n",
       "2                   NaN                   NaT            NaN              NaN   \n",
       "3                   NaN                   NaT            NaN              NaN   \n",
       "4                   NaN                   NaT            NaN              NaN   \n",
       "\n",
       "   NAWQC_Health_F_unit  NAWQC_Health_F_date  \n",
       "0                  NaN           2015-06-29  \n",
       "1                  NaN                  NaT  \n",
       "2                  NaN                  NaT  \n",
       "3                  NaN                  NaT  \n",
       "4                  NaN                  NaT  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ca_pollutant_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_pollutant_info.iloc[:, :2] = ca_pollutant_info.iloc[:, :2].replace(to_replace=np.nan, value=\"\")\n",
    "#names = set(ca_pollutant_info[\"Name1\"].str.lower().tolist()) # gives us all the names we're working with\n",
    "ca_pollutant_info[\"Name1\"] = ca_pollutant_info[\"Name1\"].str.lower()\n",
    "names = ca_pollutant_info[\"Name1\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# all_params = list(all_filtered_params.keys())# + list(unfiltered_params_2.keys())\n",
    "# rows_containing_pollutant = [] # will be used to grab the rows from ca_pollutant_info\n",
    "# names_of_pollutant = []        # \n",
    "# common_pollutants_p = []\n",
    "# reverse_params_def_dict = {}\n",
    "# temp_supposedly_intersecting = set()\n",
    "# for column in all_params:\n",
    "#     if np.any(names.str.match(column)):\n",
    "#         temp_supposedly_intersecting.add(column)\n",
    "#         match_col = np.where(names.str.match(column))[0]\n",
    "#         #print(column, match_col, type(match_col))\n",
    "#         rows_containing_pollutant += match_col.tolist()\n",
    "#         for i in range(len(match_col)):\n",
    "#             names_of_pollutant.append(column)\n",
    "#         for p_column in all_filtered_params[column]:\n",
    "#             reverse_params_def_dict[p_column] = column\n",
    "#             common_pollutants_p.append(p_column)\n",
    "#         count += 1\n",
    "# total_data = pd.concat([data_to_use[needed_params], data_to_use_numbers[common_pollutants_p]], axis=1)\n",
    "#reverse_params_def_dict = {column:pollutant for column,pollutant in zip(common_pollutants_p,names_of_pollutant)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1,4-dichlorobenzene',\n",
       " '2,4,5-t',\n",
       " '2,4-d',\n",
       " '2-methyl-4,6-dinitrophenol',\n",
       " '2-methylnaphthalene',\n",
       " '4-chloro-2-methylphenol',\n",
       " 'acetochlor',\n",
       " 'acetophenone',\n",
       " 'acifluorfen',\n",
       " 'alachlor',\n",
       " 'aldicarb',\n",
       " 'aldicarb sulfone',\n",
       " 'aldicarb sulfoxide',\n",
       " 'aldrin',\n",
       " 'alkalinity',\n",
       " 'alpha-endosulfan',\n",
       " 'alpha-hch',\n",
       " 'aluminum',\n",
       " 'anthracene',\n",
       " 'antimony',\n",
       " 'arsenic',\n",
       " 'atrazine',\n",
       " 'azinphos-methyl',\n",
       " 'barium',\n",
       " 'benfluralin',\n",
       " 'benomyl',\n",
       " 'bentazon',\n",
       " 'beryllium',\n",
       " 'bisphenol a',\n",
       " 'boron',\n",
       " 'bromacil',\n",
       " 'bromide',\n",
       " 'bromoxynil',\n",
       " 'butylate',\n",
       " 'cadmium',\n",
       " 'camphor',\n",
       " 'carbaryl',\n",
       " 'carbazole',\n",
       " 'carbofuran',\n",
       " 'chloride',\n",
       " 'chlorimuron-ethyl',\n",
       " 'chlorothalonil',\n",
       " 'chlorpyrifos',\n",
       " 'chromium',\n",
       " 'cobalt',\n",
       " 'copper',\n",
       " 'cyanazine',\n",
       " 'cyanide',\n",
       " 'cypermethrin',\n",
       " 'dcpa',\n",
       " 'diazinon',\n",
       " 'dicamba',\n",
       " 'dichlorvos',\n",
       " 'dicrotophos',\n",
       " 'dieldrin',\n",
       " 'diethyl phthalate',\n",
       " 'dinoseb',\n",
       " 'diphenamid',\n",
       " 'disulfoton',\n",
       " 'diuron',\n",
       " 'endosulfan sulfate',\n",
       " 'endrin',\n",
       " 'ethane',\n",
       " 'ethion',\n",
       " 'fenamiphos',\n",
       " 'fluometuron',\n",
       " 'fluoranthene',\n",
       " 'fluoride',\n",
       " 'fonofos',\n",
       " 'heptachlor',\n",
       " 'heptachlor epoxide',\n",
       " 'hexazinone',\n",
       " 'hydrogen',\n",
       " 'imazaquin',\n",
       " 'iodide',\n",
       " 'iprodione',\n",
       " 'iron',\n",
       " 'isophorone',\n",
       " 'isopropylbenzene',\n",
       " 'lead',\n",
       " 'lindane',\n",
       " 'linuron',\n",
       " 'malathion',\n",
       " 'manganese',\n",
       " 'mercury',\n",
       " 'metalaxyl',\n",
       " 'methidathion',\n",
       " 'methomyl',\n",
       " 'methyl parathion',\n",
       " 'metolachlor',\n",
       " 'metribuzin',\n",
       " 'molinate',\n",
       " 'molybdenum',\n",
       " 'naphthalene',\n",
       " 'napropamide',\n",
       " 'nickel',\n",
       " 'nitrate',\n",
       " 'nitrite',\n",
       " 'norflurazon',\n",
       " 'oryzalin',\n",
       " 'oxamyl',\n",
       " \"p,p'-ddd\",\n",
       " \"p,p'-dde\",\n",
       " \"p,p'-ddt\",\n",
       " 'p-cresol',\n",
       " 'parathion',\n",
       " 'pcbs',\n",
       " 'pendimethalin',\n",
       " 'perchlorate',\n",
       " 'phenanthrene',\n",
       " 'phenol',\n",
       " 'phorate',\n",
       " 'phosmet',\n",
       " 'phosphorus',\n",
       " 'picloram',\n",
       " 'prometon',\n",
       " 'prometryn',\n",
       " 'propachlor',\n",
       " 'propane',\n",
       " 'propanil',\n",
       " 'propargite',\n",
       " 'propham',\n",
       " 'propiconazole',\n",
       " 'pyrene',\n",
       " 'radium-226',\n",
       " 'radium-228',\n",
       " 'selenium',\n",
       " 'silver',\n",
       " 'simazine',\n",
       " 'sodium',\n",
       " 'strontium',\n",
       " 'sulfate',\n",
       " 'tebuthiuron',\n",
       " 'terbacil',\n",
       " 'terbufos',\n",
       " 'thallium',\n",
       " 'thiobencarb',\n",
       " 'toxaphene',\n",
       " 'triallate',\n",
       " 'trifluralin',\n",
       " 'vanadium',\n",
       " 'warfarin'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "names = set(ca_pollutant_info[\"Name1\"].tolist())\n",
    "all_params = set(list(all_filtered_params.keys()))\n",
    "rows_containing_pollutant = [] # will be used to grab the rows from ca_pollutant_info\n",
    "names_of_pollutant = []        # \n",
    "common_pollutants_p = []\n",
    "reverse_params_def_dict = {}\n",
    "for column in names.intersection(all_params):\n",
    "    match_col = [i for i,name in enumerate(names) if name == column]\n",
    "    #print(column, match_col, type(match_col))\n",
    "    rows_containing_pollutant += match_col\n",
    "    for i in range(len(match_col)):\n",
    "        names_of_pollutant.append(column)\n",
    "    for p_column in all_filtered_params[column]:\n",
    "        reverse_params_def_dict[p_column] = column\n",
    "        common_pollutants_p.append(p_column)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(names.str.match(\"aldrin\"))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 8,\n",
       " 13,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 14,\n",
       " 16,\n",
       " 17,\n",
       " 22,\n",
       " 25,\n",
       " 28,\n",
       " 30,\n",
       " 31,\n",
       " 36,\n",
       " 38,\n",
       " 40,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 51,\n",
       " 52,\n",
       " 58,\n",
       " 60,\n",
       " 62,\n",
       " 66,\n",
       " 68,\n",
       " 69,\n",
       " 74,\n",
       " 73,\n",
       " 75,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 92,\n",
       " 93,\n",
       " 97,\n",
       " 96,\n",
       " 98,\n",
       " 101,\n",
       " 104,\n",
       " 107,\n",
       " 110,\n",
       " 112,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 118,\n",
       " 119,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 128,\n",
       " 130,\n",
       " 131,\n",
       " 135,\n",
       " 137,\n",
       " 139,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 148,\n",
       " 150,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 166,\n",
       " 168,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 178,\n",
       " 177,\n",
       " 182,\n",
       " 183,\n",
       " 185,\n",
       " 187,\n",
       " 191,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 197,\n",
       " 199,\n",
       " 200,\n",
       " 201,\n",
       " 207,\n",
       " 213,\n",
       " 214,\n",
       " 215,\n",
       " 217,\n",
       " 219,\n",
       " 220,\n",
       " 222,\n",
       " 223,\n",
       " 224,\n",
       " 228,\n",
       " 229,\n",
       " 230,\n",
       " 233,\n",
       " 235,\n",
       " 236,\n",
       " 238,\n",
       " 237,\n",
       " 243,\n",
       " 244,\n",
       " 245,\n",
       " 246,\n",
       " 247,\n",
       " 250,\n",
       " 251,\n",
       " 252,\n",
       " 254,\n",
       " 257,\n",
       " 258,\n",
       " 259,\n",
       " 260,\n",
       " 261]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_names = names.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188 188\n"
     ]
    }
   ],
   "source": [
    "print(len(common_pollutants_p), len(reverse_params_def_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_pollutants_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142\n"
     ]
    }
   ],
   "source": [
    "#print(sorted(rows_containing_pollutant))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(names.str.match('benzo[a]pyrene'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names_of_pollutant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 90)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_ca_pollutant_info = ca_pollutant_info.iloc[rows_containing_pollutant, :]\n",
    "chosen_ca_pollutant_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CA_Sec_MCL_2</th>\n",
       "      <th>USEPA_Prim_MCL</th>\n",
       "      <th>USEPA_Prim_MCL_2</th>\n",
       "      <th>USEPA_Sec_MCL</th>\n",
       "      <th>USEPA_Sec_MCL_2</th>\n",
       "      <th>USEPA_MCL_Goal</th>\n",
       "      <th>USEPA_MCL_Goal_2</th>\n",
       "      <th>CA_PHG</th>\n",
       "      <th>CA_PHG_2</th>\n",
       "      <th>CA_Action_Level</th>\n",
       "      <th>...</th>\n",
       "      <th>CA_Inland_Health_DW</th>\n",
       "      <th>CA_Inland_Health_DW_2</th>\n",
       "      <th>CA_Inland_Health_Other</th>\n",
       "      <th>CA_Inland_Health_Other_2</th>\n",
       "      <th>CA_BayEst_Health</th>\n",
       "      <th>CA_BayEst_Health_2</th>\n",
       "      <th>NAWQC_Health_WF</th>\n",
       "      <th>NAWQC_Health_WF_2</th>\n",
       "      <th>NAWQC_Health_F</th>\n",
       "      <th>NAWQC_Health_F_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>NaN</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CA_Sec_MCL_2  USEPA_Prim_MCL  USEPA_Prim_MCL_2  USEPA_Sec_MCL  \\\n",
       "187           NaN          1000.0               NaN            NaN   \n",
       "186           NaN         10000.0               NaN            NaN   \n",
       "208           NaN             NaN               NaN            NaN   \n",
       "209           NaN             NaN               NaN            NaN   \n",
       "91            NaN           200.0               NaN            NaN   \n",
       "\n",
       "     USEPA_Sec_MCL_2  USEPA_MCL_Goal  USEPA_MCL_Goal_2   CA_PHG  CA_PHG_2  \\\n",
       "187              NaN          1000.0               NaN   1000.0    1000.0   \n",
       "186              NaN         10000.0               NaN  10000.0   10000.0   \n",
       "208              NaN             NaN               NaN      NaN       NaN   \n",
       "209              NaN             NaN               NaN      NaN       NaN   \n",
       "91               NaN           200.0               NaN    150.0       NaN   \n",
       "\n",
       "     CA_Action_Level        ...         CA_Inland_Health_DW  \\\n",
       "187              NaN        ...                         NaN   \n",
       "186              NaN        ...                         NaN   \n",
       "208              NaN        ...                         NaN   \n",
       "209              NaN        ...                         NaN   \n",
       "91               NaN        ...                       700.0   \n",
       "\n",
       "     CA_Inland_Health_DW_2  CA_Inland_Health_Other  CA_Inland_Health_Other_2  \\\n",
       "187                    NaN                     NaN                       NaN   \n",
       "186                    NaN                     NaN                       NaN   \n",
       "208                    NaN                     NaN                       NaN   \n",
       "209                    NaN                     NaN                       NaN   \n",
       "91                     NaN                220000.0                       NaN   \n",
       "\n",
       "     CA_BayEst_Health  CA_BayEst_Health_2  NAWQC_Health_WF  NAWQC_Health_WF_2  \\\n",
       "187               NaN                 NaN              NaN                NaN   \n",
       "186               NaN                 NaN          10000.0                NaN   \n",
       "208               NaN                 NaN              NaN                NaN   \n",
       "209               NaN                 NaN              NaN                NaN   \n",
       "91           220000.0                 NaN              4.0                NaN   \n",
       "\n",
       "     NAWQC_Health_F  NAWQC_Health_F_2  \n",
       "187             NaN               NaN  \n",
       "186             NaN               NaN  \n",
       "208             NaN               NaN  \n",
       "209             NaN               NaN  \n",
       "91            400.0               NaN  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cols = [column for column in chosen_ca_pollutant_info.columns.values.tolist()[7:] if \"unit\" not in column and \"date\" not in column and \"Ag_Goals\" not in column]#and \"_2\" not in column]\n",
    "chosen_ca_pollutant_data = chosen_ca_pollutant_info[data_cols]\n",
    "chosen_ca_pollutant_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For checking the min values\n",
    "#min_counts = []\n",
    "#row_num = []\n",
    "#for row in chosen_ca_pollutant_data.iterrows():\n",
    "#    min_count = 999999999999\n",
    "#    nonna_count = 0\n",
    "#    for item in row[1]:\n",
    "#        #if type(item) != float:\n",
    "#        #    item = np.nan\n",
    "#        if not np.isnan(item):\n",
    "#            nonna_count += 1\n",
    "#            if item < min_count:\n",
    "#                min_count = item\n",
    "#    \n",
    "#    if min_count != 999999999999:\n",
    "#        min_counts.append(min_count)\n",
    "#        row_num.append(row[0])\n",
    "#print(min_counts)\n",
    "#print(row_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "USEPA_Prim_MCL           15.00\n",
       "CA_PHG                    0.20\n",
       "CalEPA_Cancer_Potency     4.10\n",
       "Prop65_Cancer             7.50\n",
       "Prop65_Repro              0.25\n",
       "Name: 166, dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = chosen_ca_pollutant_data.iloc[19,:]\n",
    "x[(x.notna()) &  (x>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_threshold_minimum(x):\n",
    "    x_data = x[(x.notna()) &  (x > 0)]\n",
    "    if len(x_data) > 0:\n",
    "        return min(x_data)\n",
    "    else:\n",
    "        return 999999999\n",
    "    \n",
    "min_thresholds = chosen_ca_pollutant_data.apply(find_threshold_minimum, axis=1)\n",
    "min_thresholds_cols = chosen_ca_pollutant_data.idxmin(axis=1)\n",
    "#min_thresholds_cols = min_thresholds_cols[min_thresholds_cols.notna()]\n",
    "#min_thresholds = chosen_ca_pollutant_data[min_thresholds_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cyanide\n",
      "4.0 220000.0\n",
      "\n",
      "\n",
      "arsenic\n",
      "0.0014 10.0\n",
      "\n",
      "\n",
      "beryllium\n",
      "1.0 30000.0\n",
      "\n",
      "\n",
      "cadmium\n",
      "0.0023 5.0\n",
      "\n",
      "\n",
      "chromium(vi)\n",
      "0.02 21.0\n",
      "\n",
      "\n",
      "antimony\n",
      "1.0 4300.0\n",
      "\n",
      "\n",
      "alpha-hch\n",
      "0.0039 500.0\n",
      "\n",
      "\n",
      "p,p'-dde\n",
      "0.00059 1.0\n",
      "\n",
      "\n",
      "aldrin\n",
      "8e-05 0.3\n",
      "\n",
      "\n",
      "lindane\n",
      "0.019 500.0\n",
      "\n",
      "\n",
      "p,p'-ddd\n",
      "0.00083 1.0\n",
      "\n",
      "\n",
      "p,p'-ddt\n",
      "0.00059 3.5\n",
      "\n",
      "\n",
      "dieldrin\n",
      "0.00014 0.5\n",
      "\n",
      "\n",
      "toxaphene\n",
      "0.00073 8.75\n",
      "\n",
      "\n",
      "heptachlor\n",
      "0.00021 10.0\n",
      "\n",
      "\n",
      "151    heptachlor epoxide\n",
      "151    heptachlor epoxide\n",
      "Name: Name1, dtype: object\n",
      "0.0001 10.0\n",
      "\n",
      "\n",
      "151    heptachlor epoxide\n",
      "151    heptachlor epoxide\n",
      "Name: Name1, dtype: object\n",
      "0.0001 10.0\n",
      "\n",
      "\n",
      "pcbs\n",
      "0.00017 50.0\n",
      "\n",
      "\n",
      "2,4-dinitrophenol\n",
      "10.0 14000.0\n",
      "\n",
      "\n",
      "2,4-dinitrotoluene\n",
      "0.05 1000.0\n",
      "\n",
      "\n",
      "alachlor\n",
      "0.4 700.0\n",
      "\n",
      "\n",
      "acifluorfen\n",
      "1.0 2000.0\n",
      "\n",
      "\n",
      "phenol\n",
      "2000.0 4600000.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for row in chosen_ca_pollutant_data.iterrows():\n",
    "    x = row[1]\n",
    "    x_data = x[(x.notna()) &  (x > 0)]\n",
    "    if len(x_data) > 0:\n",
    "        if max(x_data)/min(x_data) > 1000:\n",
    "            print(chosen_ca_pollutant_info[\"Name1\"][row[0]])\n",
    "            print(min(x_data), max(x_data), )\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#names_of_pollutant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(min_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(min_thresholds_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rows_containing_pollutant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pollutant</th>\n",
       "      <th>Min Value</th>\n",
       "      <th>Threshold Adhered To</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>nitrite</td>\n",
       "      <td>700.0</td>\n",
       "      <td>USEPA_IRIS_RfD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>nitrate</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>USEPA_Prim_MCL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>phosphorus</td>\n",
       "      <td>0.1</td>\n",
       "      <td>USEPA_HA_NonCancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>cyanide</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NAWQC_Health_WF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>sodium</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>USEPA_HA_NonCancer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Pollutant  Min Value Threshold Adhered To\n",
       "187     nitrite      700.0       USEPA_IRIS_RfD\n",
       "186     nitrate    10000.0       USEPA_Prim_MCL\n",
       "209  phosphorus        0.1   USEPA_HA_NonCancer\n",
       "91      cyanide        4.0      NAWQC_Health_WF\n",
       "229      sodium    20000.0   USEPA_HA_NonCancer"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ca_pollutant_thresholds = pd.DataFrame({\"Pollutant\":names_of_pollutant, \"Min Value\":min_thresholds, \"Threshold Adhered To\":min_thresholds_cols})\n",
    "ca_pollutant_thresholds = ca_pollutant_thresholds[ca_pollutant_thresholds[\"Threshold Adhered To\"].notna()]\n",
    "ca_pollutant_thresholds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_pollutants_p = []\n",
    "reverse_params_def_dict = {}\n",
    "for pollutant in ca_pollutant_thresholds[\"Pollutant\"]:\n",
    "    for column in all_filtered_params[pollutant]:\n",
    "        reverse_params_def_dict[column] = pollutant\n",
    "        common_pollutants_p.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 3)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ca_pollutant_thresholds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['p00613',\n",
       " 'p71856',\n",
       " 'p00618',\n",
       " 'p71851',\n",
       " 'p00666',\n",
       " 'p00721',\n",
       " 'p00930',\n",
       " 'p00940',\n",
       " 'p00945',\n",
       " 'p00950',\n",
       " 'p91002',\n",
       " 'p01000',\n",
       " 'p01001',\n",
       " 'p01003',\n",
       " 'p01005',\n",
       " 'p01006',\n",
       " 'p01010',\n",
       " 'p01020',\n",
       " 'p01025',\n",
       " 'p01026',\n",
       " 'p01028',\n",
       " 'p01030',\n",
       " 'p01031',\n",
       " 'p01030',\n",
       " 'p01031',\n",
       " 'p01040',\n",
       " 'p01041',\n",
       " 'p01043',\n",
       " 'p01044',\n",
       " 'p01046',\n",
       " 'p01170',\n",
       " 'p01049',\n",
       " 'p01050',\n",
       " 'p01052',\n",
       " 'p01054',\n",
       " 'p01056',\n",
       " 'p01057',\n",
       " 'p01060',\n",
       " 'p01065',\n",
       " 'p01066',\n",
       " 'p01068',\n",
       " 'p01075',\n",
       " 'p01076',\n",
       " 'p01080',\n",
       " 'p01085',\n",
       " 'p01095',\n",
       " 'p01106',\n",
       " 'p01145',\n",
       " 'p01146',\n",
       " 'p01148',\n",
       " 'p04024',\n",
       " 'p04025',\n",
       " 'p04028',\n",
       " 'p04029',\n",
       " 'p63189',\n",
       " 'p04032',\n",
       " 'p82665',\n",
       " 'p04033',\n",
       " 'p04035',\n",
       " 'p04036',\n",
       " 'p04037',\n",
       " 'p63226',\n",
       " 'p04041',\n",
       " 'p04095',\n",
       " 'p09503',\n",
       " 'p09511',\n",
       " 'p34253',\n",
       " 'p34362',\n",
       " 'p39389',\n",
       " 'p34653',\n",
       " 'p39368',\n",
       " 'p38442',\n",
       " 'p38454',\n",
       " 'p38478',\n",
       " 'p82666',\n",
       " 'p38711',\n",
       " 'p38775',\n",
       " 'p38811',\n",
       " 'p38866',\n",
       " 'p38933',\n",
       " 'p63195',\n",
       " 'p39333',\n",
       " 'p39341',\n",
       " 'p39343',\n",
       " 'p39363',\n",
       " 'p39373',\n",
       " 'p39381',\n",
       " 'p39383',\n",
       " 'p39393',\n",
       " 'p39403',\n",
       " 'p39413',\n",
       " 'p39413',\n",
       " 'p39415',\n",
       " 'p63218',\n",
       " 'p39423',\n",
       " 'p39519',\n",
       " 'p39532',\n",
       " 'p39542',\n",
       " 'p39572',\n",
       " 'p63198',\n",
       " 'p39632',\n",
       " 'p63182',\n",
       " 'p39732',\n",
       " 'p39732',\n",
       " 'p39732',\n",
       " 'p39732',\n",
       " 'p39742',\n",
       " 'p99958',\n",
       " 'p46342',\n",
       " 'p49236',\n",
       " 'p49260',\n",
       " 'p49291',\n",
       " 'p49292',\n",
       " 'p49293',\n",
       " 'p49296',\n",
       " 'p49299',\n",
       " 'p49300',\n",
       " 'p49301',\n",
       " 'p49306',\n",
       " 'p49309',\n",
       " 'p82674',\n",
       " 'p49310',\n",
       " 'p82680',\n",
       " 'p49311',\n",
       " 'p49312',\n",
       " 'p49312',\n",
       " 'p49312',\n",
       " 'p49313',\n",
       " 'p49314',\n",
       " 'p49315',\n",
       " 'p50300',\n",
       " 'p50306',\n",
       " 'p50356',\n",
       " 'p50359',\n",
       " 'p61596',\n",
       " 'p50471',\n",
       " 'p61586',\n",
       " 'p61590',\n",
       " 'p61591',\n",
       " 'p61593',\n",
       " 'p61598',\n",
       " 'p61601',\n",
       " 'p62024',\n",
       " 'p63163',\n",
       " 'p63168',\n",
       " 'p63178',\n",
       " 'p63180',\n",
       " 'p63188',\n",
       " 'p63194',\n",
       " 'p63202',\n",
       " 'p63208',\n",
       " 'p63212',\n",
       " 'p63213',\n",
       " 'p63220',\n",
       " 'p63225',\n",
       " 'p63227',\n",
       " 'p63790',\n",
       " 'p71865',\n",
       " 'p71870',\n",
       " 'p71890',\n",
       " 'p71895',\n",
       " 'p71921',\n",
       " 'p81366',\n",
       " 'p82346',\n",
       " 'p82630',\n",
       " 'p82661',\n",
       " 'p82664',\n",
       " 'p82667',\n",
       " 'p82670',\n",
       " 'p82671',\n",
       " 'p82673',\n",
       " 'p82675',\n",
       " 'p82677',\n",
       " 'p82678',\n",
       " 'p82679',\n",
       " 'p82681',\n",
       " 'p82682',\n",
       " 'p82683',\n",
       " 'p82684',\n",
       " 'p82685',\n",
       " 'p82686']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_pollutants_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel test for new pollutant data - WORKS\n",
    "column = \"p01010\"\n",
    "threshold = ca_pollutant_thresholds[\"Min Value\"][ca_pollutant_thresholds[\"Pollutant\"]==reverse_params_def_dict[column]]\n",
    "actual_threshold = threshold.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passed_threshold = gives gauges that exceeded threshold\n",
    "passed_threshold = total_data[column][total_data[column].notna()] > actual_threshold\n",
    "has_passed_site = total_data[\"site_no\"][total_data[column].notna()][passed_threshold]\n",
    "has_passed_nums = total_data[column][total_data[column].notna()][passed_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['site_no',\n",
       " 'sample_dt',\n",
       " 'sample_tm',\n",
       " 'p00613',\n",
       " 'p71856',\n",
       " 'p00618',\n",
       " 'p71851',\n",
       " 'p00666',\n",
       " 'p00721',\n",
       " 'p00930',\n",
       " 'p00940',\n",
       " 'p00945',\n",
       " 'p00950',\n",
       " 'p91002',\n",
       " 'p01000',\n",
       " 'p01001',\n",
       " 'p01003',\n",
       " 'p01005',\n",
       " 'p01006',\n",
       " 'p01010',\n",
       " 'p01020',\n",
       " 'p01025',\n",
       " 'p01026',\n",
       " 'p01028',\n",
       " 'p01030',\n",
       " 'p01031',\n",
       " 'p01035',\n",
       " 'p01036',\n",
       " 'p01040',\n",
       " 'p01041',\n",
       " 'p01043',\n",
       " 'p01044',\n",
       " 'p01046',\n",
       " 'p01170',\n",
       " 'p01049',\n",
       " 'p01050',\n",
       " 'p01052',\n",
       " 'p01054',\n",
       " 'p01056',\n",
       " 'p01057',\n",
       " 'p01060',\n",
       " 'p01065',\n",
       " 'p01066',\n",
       " 'p01068',\n",
       " 'p01075',\n",
       " 'p01076',\n",
       " 'p01080',\n",
       " 'p01085',\n",
       " 'p01095',\n",
       " 'p01106',\n",
       " 'p01145',\n",
       " 'p01146',\n",
       " 'p01148',\n",
       " 'p04024',\n",
       " 'p04025',\n",
       " 'p04028',\n",
       " 'p04029',\n",
       " 'p63189',\n",
       " 'p04032',\n",
       " 'p82665',\n",
       " 'p04033',\n",
       " 'p04035',\n",
       " 'p04036',\n",
       " 'p04037',\n",
       " 'p63226',\n",
       " 'p04041',\n",
       " 'p04095',\n",
       " 'p09503',\n",
       " 'p09511',\n",
       " 'p29801',\n",
       " 'p29802',\n",
       " 'p39036',\n",
       " 'p39086',\n",
       " 'p34253',\n",
       " 'p34362',\n",
       " 'p39389',\n",
       " 'p34653',\n",
       " 'p39368',\n",
       " 'p38442',\n",
       " 'p38454',\n",
       " 'p38478',\n",
       " 'p82666',\n",
       " 'p38711',\n",
       " 'p38775',\n",
       " 'p38811',\n",
       " 'p38866',\n",
       " 'p38933',\n",
       " 'p63195',\n",
       " 'p39333',\n",
       " 'p39341',\n",
       " 'p39343',\n",
       " 'p39363',\n",
       " 'p39373',\n",
       " 'p39381',\n",
       " 'p39383',\n",
       " 'p39393',\n",
       " 'p39403',\n",
       " 'p39413',\n",
       " 'p39415',\n",
       " 'p63218',\n",
       " 'p39423',\n",
       " 'p39519',\n",
       " 'p39532',\n",
       " 'p39542',\n",
       " 'p39572',\n",
       " 'p63198',\n",
       " 'p39632',\n",
       " 'p63182',\n",
       " 'p39732',\n",
       " 'p39742',\n",
       " 'p99958',\n",
       " 'p46342',\n",
       " 'p49236',\n",
       " 'p49260',\n",
       " 'p49291',\n",
       " 'p49292',\n",
       " 'p49293',\n",
       " 'p49296',\n",
       " 'p49299',\n",
       " 'p49300',\n",
       " 'p49301',\n",
       " 'p49306',\n",
       " 'p49309',\n",
       " 'p82674',\n",
       " 'p49310',\n",
       " 'p82680',\n",
       " 'p49311',\n",
       " 'p49312',\n",
       " 'p49313',\n",
       " 'p49314',\n",
       " 'p49315',\n",
       " 'p50300',\n",
       " 'p50306',\n",
       " 'p50356',\n",
       " 'p50359',\n",
       " 'p61596',\n",
       " 'p50471',\n",
       " 'p51189',\n",
       " 'p61586',\n",
       " 'p61590',\n",
       " 'p61591',\n",
       " 'p61593',\n",
       " 'p61598',\n",
       " 'p61601',\n",
       " 'p61633',\n",
       " 'p62024',\n",
       " 'p63163',\n",
       " 'p63168',\n",
       " 'p63178',\n",
       " 'p63180',\n",
       " 'p63188',\n",
       " 'p63192',\n",
       " 'p63194',\n",
       " 'p63202',\n",
       " 'p63208',\n",
       " 'p63212',\n",
       " 'p63213',\n",
       " 'p63220',\n",
       " 'p63222',\n",
       " 'p63224',\n",
       " 'p63225',\n",
       " 'p63227',\n",
       " 'p63790',\n",
       " 'p68824',\n",
       " 'p68832',\n",
       " 'p68826',\n",
       " 'p68834',\n",
       " 'p71865',\n",
       " 'p71870',\n",
       " 'p71890',\n",
       " 'p71895',\n",
       " 'p71921',\n",
       " 'p81366',\n",
       " 'p82346',\n",
       " 'p82630',\n",
       " 'p82661',\n",
       " 'p82664',\n",
       " 'p82667',\n",
       " 'p82670',\n",
       " 'p82671',\n",
       " 'p82673',\n",
       " 'p82675',\n",
       " 'p82677',\n",
       " 'p82678',\n",
       " 'p82679',\n",
       " 'p82681',\n",
       " 'p82682',\n",
       " 'p82683',\n",
       " 'p82684',\n",
       " 'p82685',\n",
       " 'p82686']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_write_to_file = \"\"\n",
    "header = \"Site\\tPollutant\\tDate\\t% Error\\tValue\\tThreshold\\tThreshold Adhered To\\n\"\n",
    "formatSTR = \"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n\"\n",
    "pollutant_col = \"Pollutant\"\n",
    "threshold_col = \"Min Value\"\n",
    "which_threshold_col = \"Threshold Adhered To\"\n",
    "date_col = \"sample_dt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p00613': 'nitrite',\n",
       " 'p71856': 'nitrite',\n",
       " 'p00618': 'nitrate',\n",
       " 'p71851': 'nitrate',\n",
       " 'p00666': 'phosphorus',\n",
       " 'p00721': 'cyanide',\n",
       " 'p00930': 'sodium',\n",
       " 'p00940': 'chloride',\n",
       " 'p00945': 'sulfate',\n",
       " 'p00950': 'fluoride',\n",
       " 'p91002': 'fluoride',\n",
       " 'p01000': 'arsenic',\n",
       " 'p01001': 'arsenic',\n",
       " 'p01003': 'arsenic',\n",
       " 'p01005': 'barium',\n",
       " 'p01006': 'barium',\n",
       " 'p01010': 'beryllium',\n",
       " 'p01020': 'boron',\n",
       " 'p01025': 'cadmium',\n",
       " 'p01026': 'cadmium',\n",
       " 'p01028': 'cadmium',\n",
       " 'p01030': 'chromium',\n",
       " 'p01031': 'chromium',\n",
       " 'p01040': 'copper',\n",
       " 'p01041': 'copper',\n",
       " 'p01043': 'copper',\n",
       " 'p01044': 'iron',\n",
       " 'p01046': 'iron',\n",
       " 'p01170': 'iron',\n",
       " 'p01049': 'lead',\n",
       " 'p01050': 'lead',\n",
       " 'p01052': 'lead',\n",
       " 'p01054': 'manganese',\n",
       " 'p01056': 'manganese',\n",
       " 'p01057': 'thallium',\n",
       " 'p01060': 'molybdenum',\n",
       " 'p01065': 'nickel',\n",
       " 'p01066': 'nickel',\n",
       " 'p01068': 'nickel',\n",
       " 'p01075': 'silver',\n",
       " 'p01076': 'silver',\n",
       " 'p01080': 'strontium',\n",
       " 'p01085': 'vanadium',\n",
       " 'p01095': 'antimony',\n",
       " 'p01106': 'aluminum',\n",
       " 'p01145': 'selenium',\n",
       " 'p01146': 'selenium',\n",
       " 'p01148': 'selenium',\n",
       " 'p04024': 'propachlor',\n",
       " 'p04025': 'hexazinone',\n",
       " 'p04028': 'butylate',\n",
       " 'p04029': 'bromacil',\n",
       " 'p63189': 'bromacil',\n",
       " 'p04032': 'terbacil',\n",
       " 'p82665': 'terbacil',\n",
       " 'p04033': 'diphenamid',\n",
       " 'p04035': 'simazine',\n",
       " 'p04036': 'prometryn',\n",
       " 'p04037': 'prometon',\n",
       " 'p63226': 'prometon',\n",
       " 'p04041': 'cyanazine',\n",
       " 'p04095': 'fonofos',\n",
       " 'p09503': 'radium-226',\n",
       " 'p09511': 'radium-226',\n",
       " 'p34253': 'alpha-hch',\n",
       " 'p34362': 'alpha-endosulfan',\n",
       " 'p39389': 'alpha-endosulfan',\n",
       " 'p34653': \"p,p'-dde\",\n",
       " 'p39368': \"p,p'-dde\",\n",
       " 'p38442': 'dicamba',\n",
       " 'p38454': 'dicrotophos',\n",
       " 'p38478': 'linuron',\n",
       " 'p82666': 'linuron',\n",
       " 'p38711': 'bentazon',\n",
       " 'p38775': 'dichlorvos',\n",
       " 'p38811': 'fluometuron',\n",
       " 'p38866': 'oxamyl',\n",
       " 'p38933': 'chlorpyrifos',\n",
       " 'p63195': 'chlorpyrifos',\n",
       " 'p39333': 'aldrin',\n",
       " 'p39341': 'lindane',\n",
       " 'p39343': 'lindane',\n",
       " 'p39363': \"p,p'-ddd\",\n",
       " 'p39373': \"p,p'-ddt\",\n",
       " 'p39381': 'dieldrin',\n",
       " 'p39383': 'dieldrin',\n",
       " 'p39393': 'endrin',\n",
       " 'p39403': 'toxaphene',\n",
       " 'p39413': 'heptachlor',\n",
       " 'p39415': 'metolachlor',\n",
       " 'p63218': 'metolachlor',\n",
       " 'p39423': 'heptachlor epoxide',\n",
       " 'p39519': 'pcbs',\n",
       " 'p39532': 'malathion',\n",
       " 'p39542': 'parathion',\n",
       " 'p39572': 'diazinon',\n",
       " 'p63198': 'diazinon',\n",
       " 'p39632': 'atrazine',\n",
       " 'p63182': 'atrazine',\n",
       " 'p39732': '2,4-d',\n",
       " 'p39742': '2,4,5-t',\n",
       " 'p99958': '2,4,5-t',\n",
       " 'p46342': 'alachlor',\n",
       " 'p49236': 'propham',\n",
       " 'p49260': 'acetochlor',\n",
       " 'p49291': 'picloram',\n",
       " 'p49292': 'oryzalin',\n",
       " 'p49293': 'norflurazon',\n",
       " 'p49296': 'methomyl',\n",
       " 'p49299': '2-methyl-4,6-dinitrophenol',\n",
       " 'p49300': 'diuron',\n",
       " 'p49301': 'dinoseb',\n",
       " 'p49306': 'chlorothalonil',\n",
       " 'p49309': 'carbofuran',\n",
       " 'p82674': 'carbofuran',\n",
       " 'p49310': 'carbaryl',\n",
       " 'p82680': 'carbaryl',\n",
       " 'p49311': 'bromoxynil',\n",
       " 'p49312': 'aldicarb',\n",
       " 'p49313': 'aldicarb sulfone',\n",
       " 'p49314': 'aldicarb sulfoxide',\n",
       " 'p49315': 'acifluorfen',\n",
       " 'p50300': 'benomyl',\n",
       " 'p50306': 'chlorimuron-ethyl',\n",
       " 'p50356': 'imazaquin',\n",
       " 'p50359': 'metalaxyl',\n",
       " 'p61596': 'metalaxyl',\n",
       " 'p50471': 'propiconazole',\n",
       " 'p61586': 'cypermethrin',\n",
       " 'p61590': 'endosulfan sulfate',\n",
       " 'p61591': 'fenamiphos',\n",
       " 'p61593': 'iprodione',\n",
       " 'p61598': 'methidathion',\n",
       " 'p61601': 'phosmet',\n",
       " 'p62024': 'warfarin',\n",
       " 'p63163': '1,4-dichlorobenzene',\n",
       " 'p63168': '2-methylnaphthalene',\n",
       " 'p63178': 'acetophenone',\n",
       " 'p63180': 'anthracene',\n",
       " 'p63188': 'bisphenol a',\n",
       " 'p63194': 'carbazole',\n",
       " 'p63202': 'diethyl phthalate',\n",
       " 'p63208': 'fluoranthene',\n",
       " 'p63212': 'isophorone',\n",
       " 'p63213': 'isopropylbenzene',\n",
       " 'p63220': 'naphthalene',\n",
       " 'p63225': 'phenol',\n",
       " 'p63227': 'pyrene',\n",
       " 'p63790': 'perchlorate',\n",
       " 'p71865': 'iodide',\n",
       " 'p71870': 'bromide',\n",
       " 'p71890': 'mercury',\n",
       " 'p71895': 'mercury',\n",
       " 'p71921': 'mercury',\n",
       " 'p81366': 'radium-228',\n",
       " 'p82346': 'ethion',\n",
       " 'p82630': 'metribuzin',\n",
       " 'p82661': 'trifluralin',\n",
       " 'p82664': 'phorate',\n",
       " 'p82667': 'methyl parathion',\n",
       " 'p82670': 'tebuthiuron',\n",
       " 'p82671': 'molinate',\n",
       " 'p82673': 'benfluralin',\n",
       " 'p82675': 'terbufos',\n",
       " 'p82677': 'disulfoton',\n",
       " 'p82678': 'triallate',\n",
       " 'p82679': 'propanil',\n",
       " 'p82681': 'thiobencarb',\n",
       " 'p82682': 'dcpa',\n",
       " 'p82683': 'pendimethalin',\n",
       " 'p82684': 'napropamide',\n",
       " 'p82685': 'propargite',\n",
       " 'p82686': 'azinphos-methyl'}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_params_def_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going through all the p##### column names\n",
    "#  use the pollutant associated to that column to determine where there are rows for that\n",
    "#  pollutant\n",
    "# The \n",
    "for column in common_pollutants_p:\n",
    "    columns_with_pollutant_info = ca_pollutant_thresholds[pollutant_col]==reverse_params_def_dict[column]\n",
    "    threshold = ca_pollutant_thresholds[threshold_col][columns_with_pollutant_info].values[0]\n",
    "    passed_threshold = total_data[column][total_data[column].notna()] > threshold\n",
    "    has_passed_site = total_data[\"site_no\"][total_data[column].notna()][passed_threshold]\n",
    "    has_passed_nums = total_data[column][total_data[column].notna()][passed_threshold]\n",
    "    has_passed_pcts = (has_passed_nums - threshold)/threshold\n",
    "    has_passed_date = total_data[date_col][total_data[column].notna()][passed_threshold]\n",
    "    which_threshold = ca_pollutant_thresholds[which_threshold_col][ca_pollutant_thresholds[pollutant_col]==reverse_params_def_dict[column]].values[0]\n",
    "    for i in range(len(has_passed_site)):\n",
    "        to_add = formatSTR.format(has_passed_site.iloc[i], reverse_params_def_dict[column], \n",
    "                                  has_passed_date.iloc[i], has_passed_pcts.iloc[i], \n",
    "                                  has_passed_nums.iloc[i], threshold, which_threshold)\n",
    "        to_write_to_file += to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"potentially_a_bipartite_US.tsv\", \"w\")\n",
    "file.write(\"#\" + header + to_write_to_file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_by_year()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PUT IT INTO NETWORKX "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reload the file\n",
    "graph_info = pd.read_csv(\"potentially_a_bipartite_US.tsv\", sep=\"\\t\")\n",
    "display(graph_info.head())\n",
    "\n",
    "#df.groupby(['Col1', 'Col2']).size()\n",
    "graph_site_pollutant = graph_info.groupby([\"Site\", \"Pollutant\"]).size().reset_index()[[\"Site\", \"Pollutant\"]]\n",
    "display(graph_site_pollutant.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for decade in range(1970, 2030, 10):\n",
    "    graph_info[\"Date\"][0][:4]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = [tuple(row[1]) for row in graph_site_pollutant.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollutant_graph = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pollutant_graph.add_nodes_from(data_to_use['site_no'], bipartite=0)\n",
    "#pollutant_graph.add_nodes_from(filtered_params_2.keys(), bipartite=1)\n",
    "#pollutant_graph.add_nodes_from(graph_site_pollutant[\"Site\"], bipartite=0)\n",
    "#pollutant_graph.add_nodes_from(graph_site_pollutant[\"Pollutant\"], bipartite=1)\n",
    "pollutant_graph.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites, pollutants = bipartite.sets(pollutant_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max([len(i) for i in nx.connected_components(pollutant_graph)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(pollutant_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "communities = [sites, pollutants]\n",
    "colors = [\"salmon\", \"lightblue\"]\n",
    "nx.draw_networkx_edges(pollutant_graph, pos=pos, width = 1, edge_color=\"darkgray\")\n",
    "for community, color in zip(communities, colors):\n",
    "    nx.draw_networkx_nodes(pollutant_graph, pos=pos, \n",
    "                           nodelist=community,\n",
    "                           node_color=color,\n",
    "                           with_labels=False,\n",
    "                           node_size=40)\n",
    "\n",
    "    #nx.draw_networkx_labels(pollutant_graph,pos=pos)\n",
    "_=plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_graph = bipartite.projected_graph(pollutant_graph, sites)\n",
    "[len(i) for i in nx.connected_components(site_graph)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(site_graph, k=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "nx.draw_networkx_edges(site_graph, pos=pos, width = 1, edge_color=\"darkgray\")\n",
    "nx.draw_networkx_nodes(site_graph, pos=pos, with_labels=False)\n",
    "_=plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollute_graph = bipartite.projected_graph(pollutant_graph, pollutants)\n",
    "[len(i) for i in nx.connected_components(pollute_graph)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_edgelist(site_graph, \"site_graph_edges.tsv\", delimiter=\"\\t\", data = False)\n",
    "nx.write_edgelist(pollute_graph, \"pollute_graph_edges.tsv\", delimiter=\"\\t\", data = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST - IT WORKS!!!! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "column = \"p01010\"\n",
    "threshold = pollutant_info[\"Human Health for the consumption of\\xa0Water + Organism (µg/L)\"][pollutant_info[\"Pollutant (P = priority pollutant)\"]==reverse_params_def_dict[column]]\n",
    "actual_threshold = threshold.values[0]\n",
    "print(\"Column:\", reverse_params_def_dict[column], \"\\tThreshold:\", actual_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "passed_threshold = total_data[column][total_data[column].notna()] > actual_threshold\n",
    "has_passed_site = total_data[\"site_no\"][total_data[column].notna()][passed_threshold]\n",
    "has_passed_nums = total_data[column][total_data[column].notna()][passed_threshold]\n",
    "#len(passed_threshold)\n",
    "#len(total_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to_write_to_file = \"\"\n",
    "formatSTR = \"{}\\t{}\\t{}\\n\"\n",
    "pollutant_col = \"Pollutant (P = priority pollutant)\"\n",
    "threshold_col = \"Human Health for the consumption of\\xa0Water + Organism (µg/L)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for column in common_pollutants_p:\n",
    "    threshold = pollutant_info[threshold_col][pollutant_info[pollutant_col]==reverse_params_def_dict[column]].values[0]\n",
    "    passed_threshold = total_data[column][total_data[column].notna()] > threshold\n",
    "    has_passed_site = total_data[\"site_no\"][total_data[column].notna()][passed_threshold]\n",
    "    has_passed_nums = total_data[column][total_data[column].notna()][passed_threshold]\n",
    "    \n",
    "    for i in range(len(has_passed_site)):\n",
    "        to_add = formatSTR.format(has_passed_site.iloc[i], reverse_params_def_dict[column], has_passed_nums.iloc[i])\n",
    "        to_write_to_file += to_add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "file = open(\"potentially_a_bipartite.tsv\", \"w\")\n",
    "file.write(to_write_to_file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(common_pollutants_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pollutant_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tangent: Looking at the amount of data per parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how much data we have for each parameter...\n",
    "params_counts_dict = {}\n",
    "for param in a:\n",
    "    count = a.shape[0] - sum(a[param].isna())\n",
    "    if count > 0:\n",
    "        params_counts_dict[params_def_dict[param]] = count\n",
    "    \n",
    "    #print(params_def_dict[param] + \":\", count)\n",
    "params_counts = list(params_counts_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(list(params_counts_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_of_counts = {}\n",
    "for count in params_counts_dict.values():\n",
    "    if count not in counts_of_counts:\n",
    "        counts_of_counts[count] = 0\n",
    "    counts_of_counts[count] += 1\n",
    "\n",
    "param_counts = list(params_counts_dict.values())\n",
    "count_counts = list(counts_of_counts.values())\n",
    "bin_edges = np.logspace(np.log10(min(param_counts)), \n",
    "                        np.log10(max(param_counts)),\n",
    "                        num = 10)\n",
    "density, _ = np.histogram(param_counts, bins=bin_edges, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_be = np.log10(bin_edges)\n",
    "x = 10**((log_be[1:] + log_be[:-1])/2)\n",
    "\n",
    "plt.loglog(x, density, marker='o', linestyle='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
