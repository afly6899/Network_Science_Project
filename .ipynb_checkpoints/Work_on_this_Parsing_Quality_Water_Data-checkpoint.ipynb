{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps (as of October 20, 2018)\n",
    "So we got the file put into a potentially readable format for a bipartite network in networkx, but we still have a lot of work to do!\n",
    "\n",
    "**Audrey**\n",
    "* Figure out what format this file needs to be in in order to load into networkx as a bipartite\n",
    "* Create a bipartite network!\n",
    "\n",
    "**Cassie**\n",
    "* Figure out and get the thresholds for pollutants in California (esp. if they're different than what we have)\n",
    "* Put those thresholds into a format that can be easily used by the code we've written"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water Quality Network\n",
    "For our network project, Cassie and I are thinking of creating a bipartite network where the nodes are pollutants and the links are water facilities whose measurements of those pollutants are above the threshold. By doing this linking, we hope to see what the biggest pollutants are, how pollutants might connect to one another, and if there are any pollutants that we should be worried about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sources\n",
    "We got our data from USGS (U.S. Geological Survey). I'll need to get the exact link later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the data\n",
    "Since I'm not too familiar with the data, let's load it in and take a look. There's some preliminary things that I do know, which will be come prevelant when you look at the code. For instance, you can break up the code into chunks by splitting on instances of \"#\\n\". The # comes from the file header and most \"sections\" within the header are separated by # followed by a new line. The last item of the split is the actual data.\n",
    "\n",
    "Let's start by loading in everything!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MUST PIP INSTALL\n",
    "* numpy\n",
    "* pandas\n",
    "* matplotlib\n",
    "* xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name):\n",
    "    data = []\n",
    "    with open(file_name, 'r') as file:\n",
    "        data = file.read().split(\"#\\n\")\n",
    "\n",
    "    if not data:\n",
    "        print(\"File {} was unable to be read.\".format(file_name))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sections: 16\n",
      "2nd section:\n",
      "# U.S. Geological Survey\n",
      "# \n",
      "# This file contains selected water-quality data for stations in the National Water Information \n",
      "# System water-quality database.  Explanation of codes found in this file are followed by\n",
      "# the retrieved data.\n",
      "\n",
      "Number of characters in actual data: 9736982\n"
     ]
    }
   ],
   "source": [
    "file_name = \"LA_Water_Quality_Data.txt\"\n",
    "data = load_data(file_name)\n",
    "print(\"Number of sections:\", len(data))\n",
    "print(\"2nd section:\", data[2], sep = \"\\n\")\n",
    "print(\"Number of characters in actual data:\", len(data[15]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We have 15 chunks of text when doing that split (which feels a bit better than doing it line-by-line). Here's a breakdown of what's inside:\n",
    "    #  0:                               #  8: coll_ent_cd  \n",
    "    #  1: File created...               #  9: medium_cd  \n",
    "    #  2: U.S. Geological Survey        # 10: tu_id  \n",
    "    #  3: The data you have...          # 11: body_part_id  \n",
    "    #  4: To view additional...         # 12: remark_cd  \n",
    "    #  5: Param_id      - parameter     # 13: Data for the following sites...  \n",
    "    #  6: sample_start_time_datum_cd    # 14: WARNING: some preadsheet...  \n",
    "    #  7: tm_datum_rlbty_cd             # 15: Data!  \n",
    "\n",
    "I've already glanced at the file in Excel and figured out how to parse all of the parameters and their descriptions, which will probably be useful later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs the part of the header that contains the parameter label followed by its meaning\n",
    "# outputs a dictionary where the key is the label (lower case) and the value is the description\n",
    "def get_parameter_def(param_header):\n",
    "    params_dict = {}\n",
    "    params_type = {}\n",
    "    params = param_header.split(\"\\n\")\n",
    "    params_pattern = re.compile(\"# +(\\w+) +- +(.+)\")\n",
    "\n",
    "    for param in params:\n",
    "        a = params_pattern.search(param)\n",
    "\n",
    "        if a: \n",
    "            #print(first_t, a.group(1), a.group(2))\n",
    "            params_dict[a.group(1).lower()] = a.group(2)\n",
    "            #print(a.group(1) + \":\", a.group(2).split(',')[-1])\n",
    "\n",
    "    return params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters measured: 1046\n"
     ]
    }
   ],
   "source": [
    "params_dict = get_parameter_def(data[5])\n",
    "print(\"Total number of parameters measured:\", len(params_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_params = [\"site_no\", \"sample_dt\", \"sample_tm\"]\n",
    "data_params = [param for param in params_dict if param[0] == \"p\"]\n",
    "#params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7763, 1046)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency_cd</th>\n",
       "      <th>site_no</th>\n",
       "      <th>sample_dt</th>\n",
       "      <th>sample_tm</th>\n",
       "      <th>sample_end_dt</th>\n",
       "      <th>sample_end_tm</th>\n",
       "      <th>sample_start_time_datum_cd</th>\n",
       "      <th>tm_datum_rlbty_cd</th>\n",
       "      <th>coll_ent_cd</th>\n",
       "      <th>medium_cd</th>\n",
       "      <th>...</th>\n",
       "      <th>p99856</th>\n",
       "      <th>p99871</th>\n",
       "      <th>p99931</th>\n",
       "      <th>p99947</th>\n",
       "      <th>p99958</th>\n",
       "      <th>p99959</th>\n",
       "      <th>p99963</th>\n",
       "      <th>p99972</th>\n",
       "      <th>p99994</th>\n",
       "      <th>p99995</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USGS</td>\n",
       "      <td>332031118504001</td>\n",
       "      <td>2000-10-24</td>\n",
       "      <td>14:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDT</td>\n",
       "      <td>T</td>\n",
       "      <td>USGS-WRD</td>\n",
       "      <td>WG</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USGS</td>\n",
       "      <td>333420118060501</td>\n",
       "      <td>2000-11-09</td>\n",
       "      <td>09:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PST</td>\n",
       "      <td>T</td>\n",
       "      <td>USGS-WRD</td>\n",
       "      <td>WG</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1046 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  agency_cd          site_no   sample_dt sample_tm sample_end_dt  \\\n",
       "0      USGS  332031118504001  2000-10-24     14:30           NaN   \n",
       "1      USGS  333420118060501  2000-11-09     09:30           NaN   \n",
       "\n",
       "  sample_end_tm sample_start_time_datum_cd tm_datum_rlbty_cd coll_ent_cd  \\\n",
       "0           NaN                        PDT                 T    USGS-WRD   \n",
       "1           NaN                        PST                 T    USGS-WRD   \n",
       "\n",
       "  medium_cd   ...    p99856  p99871  p99931  p99947  p99958  p99959  p99963  \\\n",
       "0        WG   ...       NaN     0.0     NaN     NaN     NaN     NaN     NaN   \n",
       "1        WG   ...       NaN     0.0     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "   p99972  p99994  p99995  \n",
       "0     NaN     NaN     NaN  \n",
       "1     NaN     NaN     NaN  \n",
       "\n",
       "[2 rows x 1046 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_to_use = pd.read_csv(pd.compat.StringIO(data[15]), sep='\\t', low_memory=False, header=0, skiprows=[1])\n",
    "# I find this a bit concerning...: https://stackoverflow.com/questions/24251219/pandas-read-csv-low-memory-and-dtype-options\n",
    "# I'd want to specify type, but it seems like there's a lot of strings within supposedly numerical columns...\n",
    "print(data_to_use.shape)\n",
    "display(data_to_use.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p00003</th>\n",
       "      <th>p00004</th>\n",
       "      <th>p00005</th>\n",
       "      <th>p00008</th>\n",
       "      <th>p00009</th>\n",
       "      <th>p00010</th>\n",
       "      <th>p00011</th>\n",
       "      <th>p00020</th>\n",
       "      <th>p00021</th>\n",
       "      <th>p00025</th>\n",
       "      <th>...</th>\n",
       "      <th>p99856</th>\n",
       "      <th>p99871</th>\n",
       "      <th>p99931</th>\n",
       "      <th>p99947</th>\n",
       "      <th>p99958</th>\n",
       "      <th>p99959</th>\n",
       "      <th>p99963</th>\n",
       "      <th>p99972</th>\n",
       "      <th>p99994</th>\n",
       "      <th>p99995</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>973.0</td>\n",
       "      <td>90.7</td>\n",
       "      <td>99.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1034 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   p00003  p00004  p00005  p00008  p00009  p00010  p00011  p00020  p00021  \\\n",
       "0     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "1     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "2     NaN     NaN     NaN     NaN     NaN    18.5     NaN     NaN     NaN   \n",
       "3     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "4     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "  p00025  ...    p99856  p99871  p99931  p99947 p99958  p99959 p99963  p99972  \\\n",
       "0    NaN  ...       NaN     0.0     NaN     NaN    NaN     NaN    NaN     NaN   \n",
       "1    NaN  ...       NaN     0.0     NaN     NaN    NaN     NaN    NaN     NaN   \n",
       "2    NaN  ...       NaN     0.0     NaN     NaN    NaN     NaN    NaN   973.0   \n",
       "3    NaN  ...       NaN     NaN     NaN     NaN    NaN     NaN    NaN     NaN   \n",
       "4    NaN  ...       NaN     NaN     NaN     NaN    NaN     NaN    NaN     NaN   \n",
       "\n",
       "   p99994 p99995  \n",
       "0     NaN    NaN  \n",
       "1     NaN    NaN  \n",
       "2    90.7   99.8  \n",
       "3     NaN    NaN  \n",
       "4     NaN    NaN  \n",
       "\n",
       "[5 rows x 1034 columns]"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_use_numbers = data_to_use[data_params]\n",
    "data_to_use_numbers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_use_numbers = data_to_use_numbers.replace(\"[<> A-Za-z]\", \"\", regex=True)\n",
    "data_to_use_numbers = data_to_use_numbers.replace(\" \", \"\", regex=True)\n",
    "data_to_use_numbers = data_to_use_numbers.replace(r'^$', np.nan, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_use_numbers = data_to_use_numbers.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_data = pd.concat([data_to_use[needed_params], data_to_use_numbers], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_no</th>\n",
       "      <th>sample_dt</th>\n",
       "      <th>sample_tm</th>\n",
       "      <th>p00003</th>\n",
       "      <th>p00004</th>\n",
       "      <th>p00005</th>\n",
       "      <th>p00008</th>\n",
       "      <th>p00009</th>\n",
       "      <th>p00010</th>\n",
       "      <th>p00011</th>\n",
       "      <th>...</th>\n",
       "      <th>p99856</th>\n",
       "      <th>p99871</th>\n",
       "      <th>p99931</th>\n",
       "      <th>p99947</th>\n",
       "      <th>p99958</th>\n",
       "      <th>p99959</th>\n",
       "      <th>p99963</th>\n",
       "      <th>p99972</th>\n",
       "      <th>p99994</th>\n",
       "      <th>p99995</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>332031118504001</td>\n",
       "      <td>2000-10-24</td>\n",
       "      <td>14:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>333420118060501</td>\n",
       "      <td>2000-11-09</td>\n",
       "      <td>09:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>333420118060501</td>\n",
       "      <td>2006-08-30</td>\n",
       "      <td>08:20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>973.0</td>\n",
       "      <td>90.7</td>\n",
       "      <td>99.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>333420118060501</td>\n",
       "      <td>2006-08-30</td>\n",
       "      <td>08:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>333420118060501</td>\n",
       "      <td>2006-08-30</td>\n",
       "      <td>08:40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1037 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           site_no   sample_dt sample_tm  p00003  p00004  p00005  p00008  \\\n",
       "0  332031118504001  2000-10-24     14:30     NaN     NaN     NaN     NaN   \n",
       "1  333420118060501  2000-11-09     09:30     NaN     NaN     NaN     NaN   \n",
       "2  333420118060501  2006-08-30     08:20     NaN     NaN     NaN     NaN   \n",
       "3  333420118060501  2006-08-30     08:30     NaN     NaN     NaN     NaN   \n",
       "4  333420118060501  2006-08-30     08:40     NaN     NaN     NaN     NaN   \n",
       "\n",
       "   p00009  p00010  p00011   ...    p99856  p99871  p99931  p99947  p99958  \\\n",
       "0     NaN     NaN     NaN   ...       NaN     0.0     NaN     NaN     NaN   \n",
       "1     NaN     NaN     NaN   ...       NaN     0.0     NaN     NaN     NaN   \n",
       "2     NaN    18.5     NaN   ...       NaN     0.0     NaN     NaN     NaN   \n",
       "3     NaN     NaN     NaN   ...       NaN     NaN     NaN     NaN     NaN   \n",
       "4     NaN     NaN     NaN   ...       NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "   p99959  p99963  p99972  p99994  p99995  \n",
       "0     NaN     NaN     NaN     NaN     NaN  \n",
       "1     NaN     NaN     NaN     NaN     NaN  \n",
       "2     NaN     NaN   973.0    90.7    99.8  \n",
       "3     NaN     NaN     NaN     NaN     NaN  \n",
       "4     NaN     NaN     NaN     NaN     NaN  \n",
       "\n",
       "[5 rows x 1037 columns]"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting params into filtered and unfiltered\n",
    "* unfiltered = grab the ground water as is - you have extra sediment somehow\n",
    "* filtered = you filter out the ground water \n",
    "* do analysis with filtered and unfiltered, but DON'T MIX\n",
    "* higher pollution for unfiltered properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note\n",
    "There's some descrepencies in these parameters. We'll deal with this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_params_1 = {}\n",
    "unfiltered_params_1 = {}\n",
    "for param in params_dict.items():\n",
    "    components = param[1].split(\", \")\n",
    "    component = components[0].lower()\n",
    "    if \"filtered\" in components:\n",
    "        if component not in filtered_params_1:\n",
    "            filtered_params_1[component] = []\n",
    "        filtered_params_1[component].append(param[0])\n",
    "    elif \"unfiltered\" in components:\n",
    "        if component not in unfiltered_params_1:\n",
    "            unfiltered_params_1[component] = []\n",
    "        unfiltered_params_1[component].append(param[0])\n",
    "        \n",
    "filtered_params_2 = {}\n",
    "unfiltered_params_2 = {}\n",
    "for param in params_dict.items():\n",
    "    components = param[1].split(\", \")\n",
    "    component = components[0].lower()\n",
    "    if \"unfiltered\" not in components: #\"filtered\" in components:\n",
    "        if component not in filtered_params_2:\n",
    "            filtered_params_2[component] = []\n",
    "        filtered_params_2[component].append(param[0])\n",
    "    elif \"filtered\" not in components: #\"unfiltered\" in components:\n",
    "        if component not in unfiltered_params_2:\n",
    "            unfiltered_params_2[component] = []\n",
    "        unfiltered_params_2[component].append(param[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For first method:\n",
      "57\n",
      "197\n",
      "360\n",
      "For second method:\n",
      "127\n",
      "518\n",
      "360\n",
      "321\n",
      "0\n",
      "321\n"
     ]
    }
   ],
   "source": [
    "print(\"For first method:\")\n",
    "print(len(set(filtered_params_1).intersection(set(unfiltered_params_1))))\n",
    "print(len(filtered_params_1))\n",
    "print(len(unfiltered_params_1))\n",
    "\n",
    "print(\"For second method:\")\n",
    "print(len(set(filtered_params_2).intersection(set(unfiltered_params_2))))\n",
    "print(len(filtered_params_2))\n",
    "print(len(unfiltered_params_2))\n",
    "\n",
    "print(len(set(filtered_params_2).difference(filtered_params_1)))\n",
    "print(len(set(unfiltered_params_2).difference(unfiltered_params_1)))\n",
    "print(518-197)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is writing the params into a file\n",
    "#unfiltered_file = open(\"Unfiltered_params.txt\", \"w\")\n",
    "#filtered_file = open(\"Filtered_params.txt\", \"w\")\n",
    "#\n",
    "#for param in unfiltered_params.items():\n",
    "#    formatSTR = param[0] + \"\\t\" + \"\\t\".join(param[1]) + \"\\r\\n\"\n",
    "#    unfiltered_file.write(formatSTR.lower())\n",
    "#unfiltered_file.close()\n",
    "#for param in filtered_params.items():\n",
    "#    formatSTR = param[0] + \"\\t\" + \"\\t\".join(param[1]) + \"\\r\\n\"\n",
    "#    filtered_file.write(formatSTR.lower())\n",
    "#filtered_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Step: Getting the pollutants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollutant_file = pd.ExcelFile(\"Thresholds_hh_USGScompatible.xlsx\")\n",
    "convert_to_str = {name:str for name in pd.read_excel(\"Thresholds_hh_USGScompatible.xlsx\").columns.values.tolist()}\n",
    "pollutant_info = pollutant_file.parse(converters=convert_to_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pollutant (P = priority pollutant)</th>\n",
       "      <th>CAS Number</th>\n",
       "      <th>Human Health for the consumption of Water + Organism (µg/L)</th>\n",
       "      <th>Human Health for the consumption of Organism Only (µg/L)</th>\n",
       "      <th>Publication Year</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acenaphthene</td>\n",
       "      <td>83329</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>90</td>\n",
       "      <td>2015</td>\n",
       "      <td>The criterion for organoleptic (taste and odor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acrylonitrile</td>\n",
       "      <td>107131</td>\n",
       "      <td>6.100000e-02</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>This criterion is based on carcinogenicity of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aldrin</td>\n",
       "      <td>309002</td>\n",
       "      <td>7.700000e-07</td>\n",
       "      <td>7.7e-07</td>\n",
       "      <td>2015</td>\n",
       "      <td>This criterion is based on carcinogenicity of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alpha-hch</td>\n",
       "      <td>319846</td>\n",
       "      <td>3.600000e-04</td>\n",
       "      <td>0.00039</td>\n",
       "      <td>2015</td>\n",
       "      <td>This criterion is based on carcinogenicity of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alpha-endosulfan</td>\n",
       "      <td>959988</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>30</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Pollutant (P = priority pollutant) CAS Number  \\\n",
       "0                       acenaphthene      83329   \n",
       "1                      acrylonitrile     107131   \n",
       "2                             aldrin     309002   \n",
       "3                          alpha-hch     319846   \n",
       "4                   alpha-endosulfan     959988   \n",
       "\n",
       "   Human Health for the consumption of Water + Organism (µg/L)  \\\n",
       "0                                       7.000000e+01             \n",
       "1                                       6.100000e-02             \n",
       "2                                       7.700000e-07             \n",
       "3                                       3.600000e-04             \n",
       "4                                       2.000000e+01             \n",
       "\n",
       "  Human Health for the consumption of Organism Only (µg/L) Publication Year  \\\n",
       "0                                                 90                   2015   \n",
       "1                                                  7                   2015   \n",
       "2                                            7.7e-07                   2015   \n",
       "3                                            0.00039                   2015   \n",
       "4                                                30                    2015   \n",
       "\n",
       "                                               Notes  \n",
       "0  The criterion for organoleptic (taste and odor...  \n",
       "1  This criterion is based on carcinogenicity of ...  \n",
       "2  This criterion is based on carcinogenicity of ...  \n",
       "3  This criterion is based on carcinogenicity of ...  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pollutant_info = pollutant_info[pollutant_info[\"Pollutant (P = priority pollutant)\"].notna()]\n",
    "pollutant_info[\"Pollutant (P = priority pollutant)\"] = pollutant_info[\"Pollutant (P = priority pollutant)\"].str.strip()\n",
    "pollutant_info[\"Pollutant (P = priority pollutant)\"] = pollutant_info[\"Pollutant (P = priority pollutant)\"].str.lower()\n",
    "#pollutant_info[\"Human Health for the consumption of\\xa0Water + Organism (µg/L)\"] = pollutant_info[\"Human Health for the consumption of\\xa0Water + Organism (µg/L)\"].astype(str)\n",
    "pollutant_info[\"Human Health for the consumption of\\xa0Water + Organism (µg/L)\"] = pollutant_info[\"Human Health for the consumption of\\xa0Water + Organism (µg/L)\"].str.replace(\"<\", \"\")\n",
    "pollutant_info[\"Human Health for the consumption of\\xa0Water + Organism (µg/L)\"] = pollutant_info[\"Human Health for the consumption of\\xa0Water + Organism (µg/L)\"].str.strip()\n",
    "has_ranges = pollutant_info[\"Human Health for the consumption of\\xa0Water + Organism (µg/L)\"].str.contains(\"-\")\n",
    "ranges = pollutant_info[has_ranges]\n",
    "ranges\n",
    "pollutant_info = pollutant_info[~has_ranges]\n",
    "pollutant_info[\"Human Health for the consumption of\\xa0Water + Organism (µg/L)\"] = pd.to_numeric(pollutant_info[\"Human Health for the consumption of\\xa0Water + Organism (µg/L)\"])\n",
    "pollutant_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_pollutants_p = []\n",
    "reverse_params_dict = {}\n",
    "pollutant_info[\"Pollutant (P = priority pollutant)\"]=pollutant_info[\"Pollutant (P = priority pollutant)\"].str.lower()\n",
    "a = pollutant_info[\"Pollutant (P = priority pollutant)\"]\n",
    "a = a[a.notna()]\n",
    "for pollutant in a:\n",
    "    pollutant = pollutant\n",
    "    if pollutant in filtered_params_2:\n",
    "        for column in filtered_params_2[pollutant]:\n",
    "            common_pollutants_p.append(column)\n",
    "            reverse_params_dict[column] = pollutant\n",
    "#reverse_params_dict\n",
    "#common_pollutants_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = pd.concat([data_to_use[needed_params], data_to_use_numbers[common_pollutants_p]], axis=1)\n",
    "#data_to_use_subset.head()\n",
    "\n",
    "#total_data.notna().sum() # <- this is useful when looking at how many values each column has"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST - IT WORKS!!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: beryllium \tThreshold: 4.0\n"
     ]
    }
   ],
   "source": [
    "column = \"p01010\"\n",
    "threshold = pollutant_info[\"Human Health for the consumption of\\xa0Water + Organism (µg/L)\"][pollutant_info[\"Pollutant (P = priority pollutant)\"]==reverse_params_dict[column]]\n",
    "actual_threshold = threshold.values[0]\n",
    "print(\"Column:\", reverse_params_dict[column], \"\\tThreshold:\", actual_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "passed_threshold = total_data[column][total_data[column].notna()] > actual_threshold\n",
    "has_passed_site = total_data[\"site_no\"][total_data[column].notna()][passed_threshold]\n",
    "has_passed_nums = total_data[column][total_data[column].notna()][passed_threshold]\n",
    "#len(passed_threshold)\n",
    "#len(total_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335943118042215\tberyllium\t5.0\n",
      "335943118042224\tberyllium\t10.0\n",
      "335943118042226\tberyllium\t10.0\n",
      "335943118042228\tberyllium\t10.0\n",
      "335943118042243\tberyllium\t5.0\n",
      "344415118130501\tberyllium\t10.0\n",
      "10278300\tberyllium\t130.0\n",
      "10278300\tberyllium\t100.0\n",
      "10278300\tberyllium\t50.0\n",
      "10278300\tberyllium\t100.0\n",
      "10278300\tberyllium\t50.0\n",
      "10278300\tberyllium\t100.0\n",
      "10278300\tberyllium\t50.0\n",
      "10278300\tberyllium\t70.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_write_to_file = \"\"\n",
    "formatSTR = \"{}\\t{}\\t{}\\n\"\n",
    "pollutant_col = \"Pollutant (P = priority pollutant)\"\n",
    "threshold_col = \"Human Health for the consumption of\\xa0Water + Organism (µg/L)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in common_pollutants_p:\n",
    "    threshold = pollutant_info[threshold_col][pollutant_info[pollutant_col]==reverse_params_dict[column]].values[0]\n",
    "    passed_threshold = total_data[column][total_data[column].notna()] > threshold\n",
    "    has_passed_site = total_data[\"site_no\"][total_data[column].notna()][passed_threshold]\n",
    "    has_passed_nums = total_data[column][total_data[column].notna()][passed_threshold]\n",
    "    \n",
    "    for i in range(len(has_passed_site)):\n",
    "        to_add = formatSTR.format(has_passed_site.iloc[i], reverse_params_dict[column], has_passed_nums.iloc[i])\n",
    "        to_write_to_file += to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"potentially_a_bipartite.tsv\", \"w\")\n",
    "file.write(to_write_to_file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_pollutants_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87, 6)"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pollutant_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tangent: Looking at the amount of data per parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-376c1d821adc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Let's see how much data we have for each parameter...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mparams_counts_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "# Let's see how much data we have for each parameter...\n",
    "params_counts_dict = {}\n",
    "for param in a:\n",
    "    count = a.shape[0] - sum(a[param].isna())\n",
    "    if count > 0:\n",
    "        params_counts_dict[params_dict[param]] = count\n",
    "    \n",
    "    #print(params_dict[param] + \":\", count)\n",
    "params_counts = list(params_counts_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(list(params_counts_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_of_counts = {}\n",
    "for count in params_counts_dict.values():\n",
    "    if count not in counts_of_counts:\n",
    "        counts_of_counts[count] = 0\n",
    "    counts_of_counts[count] += 1\n",
    "\n",
    "param_counts = list(params_counts_dict.values())\n",
    "count_counts = list(counts_of_counts.values())\n",
    "bin_edges = np.logspace(np.log10(min(param_counts)), \n",
    "                        np.log10(max(param_counts)),\n",
    "                        num = 10)\n",
    "density, _ = np.histogram(param_counts, bins=bin_edges, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_be = np.log10(bin_edges)\n",
    "x = 10**((log_be[1:] + log_be[:-1])/2)\n",
    "\n",
    "plt.loglog(x, density, marker='o', linestyle='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
